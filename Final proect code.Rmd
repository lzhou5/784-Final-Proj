---
title: "Final project code"
author: "Names"
date: "11/16/2017"
output: html_document
---

```{r message=FALSE}
#source("https://bioconductor.org/biocLite.R")
#biocLite("curatedBreastData")

library("curatedBreastData")
library(SummarizedExperiment)
library(Biobase)

data(curatedBreastDataExprSetList)
cbd <- curatedBreastDataExprSetList
str(cbd[[1]])
str <- unique(protocolData(cbd[[1]])$labelDescription)

grepl("breast", str, ignore.case=T)
```

To obtain the same dataset as the paper, we had to apply two filters: (1) datsets with at least 30 samples and (2) has at least the 35 genes in PAM50. 
```{r}

#===================================# Getting the same dataset #=====================================#
#===# apply filters
samp.size <- sapply(1:length(cbd), function(i) nrow(protocolData(cbd[[i]])))
cut1 <- samp.size > 30 # checking which/how many have at least 30 samples

 #== making the first cut
names.cut1 <- names(cbd)[cut1]
cbd.cut1 <- cbd[names.cut1]

all.t <- sapply(1:34, function(i) strsplit(as.character(unique(phenoData(cbd[[i]])$datasetName)), "_")[[1]][2])
datnCuts <- cbind(all.t, cut1) # all genes and which made first cut
geo.plat.id <- sapply(1:34, function(i) strsplit(as.character(unique(phenoData(cbd[[i]])$datasetName)), "_")[[1]][3])

batch.id0 <- sapply(1:34, function(i) strsplit(as.character(unique(phenoData(cbd[[i]])$datasetName)), "_")[[1]][4])
batch.id <- ifelse(batch.id0 == "all", "", batch.id0)
#featureData(cbd[[1]])$probe

#namesofthing <- sapply(1:34, function(i) as.character(unique(phenoData(cbd[[i]])$datasetName)))


dat1 <- subset(cbd, subset=c(cut1 == 1))

#== making the second cut 
# pam50 gene set
gs0 <- c("GRB7 CEP55 MYBL2 KRT5 CDC20 UBE2C CDH3 EXO1 MELK MIA KRT14 BAG1 BIRC5 BLVRA CCNB1 CCNE1 CDC6 CENPF EGFR ERBB2 ESR1 FOXA1 FOXC1 KIF2C KRT17 MAPT MDM2 MKI67 MMP11 MYC PGR RRM2 SFRP1 SLC39A6 TYMS")
gs <- unlist(strsplit(gs0, " "))
length(gs)

cut2 <- sapply(1:length(cbd), function(i) all(gs %in% featureData(cbd[[i]])$gene_symbol))
  
# summary of which experiments made which cuts
datnCuts <- data.frame(all.t, cut1, cut2)
datnCuts[["both.cuts"]] <- with(datnCuts, cut1*cut2)
datnCuts[["sampsize"]] <- samp.size
datnCuts[["real.cut"]] <- with(datnCuts, cut2*(sampsize > 47))
datnCuts[["batch.id"]] <- batch.id
datnCuts[["geo.plat.id"]] <- geo.plat.id

datnCuts

# dataset with only those experiments that made both cuts
dat <- cbd[datnCuts$real.cut == 1]
```

Below is a summary of the final analysis dataset 
```{r}
#Table 1: Summary of our dataset 
table1 <- datnCuts[datnCuts$real.cut==1, c("all.t","batch.id","geo.plat.id","sampsize")]
names(table1) <- c("ID","Batch ID","GEO Platform ID","Samples (n)")
table1
```

Below is project analysis using final filtered data 
```{r}
#===================================# Figure 6 #=====================================#
# subtyping


#== instructions for removing duplicate genes_symbols
# For duplicated gene symbols linked to different probes in an array, the probe linked to that
# specific gene with the highest variance across all samples was kept.
# Additional Files 2

# jnk.gs <- featureData(jnk)$gene_symbol
# jnk.vars <- apply(exprs(jnk), 1, var)
# 
# thing <- data.frame(jnk.gs, jnk.vars)
# thing2 <- thing[thing$jnk.gs %in% gs,]


#=== FUNCTION: data.ready
# OBJECTIVE: for one dataset, this returns the 35 pam50 genes with the largest variance
# INPUTS:  one dataset from dat
# OUTPUT: dataset without replicates
data.ready <- function(dat){
  jnk <- dat
  jnk2 <- featureData(jnk)$gene_symbol %in% gs

  jnk.gs <- featureData(jnk)$gene_symbol
  jnk.vars <- apply(exprs(jnk), 1, function(x) var(x, na.rm=TRUE))
  
  thing <- data.frame(jnk.gs, jnk.vars)
  thing2 <- thing[thing$jnk.gs %in% gs,]

  #=== FUNCTION: compare.to.max
  # OBJECTIVE: compare the value in a row of a matrix to the max value in the cluster
  # INPUTS: the dataset (data), the row index (i), the cluster variable (clust)
  # OUTPUTS: indicator variable of whether the given row matches the cluster max
  compare.to.max <- function(i, data=thing2, clust="jnk.gs"){
    d <- data[[clust]]
    c <- d[i]
    max.c <- max(data[d == c,"jnk.vars"])
    is.max <- as.numeric(data[i,"jnk.vars"] == max.c)
    
    return(is.max)
  }
  
  is.max <- sapply(1:nrow(thing2), compare.to.max)
  
  thing3 <- data.frame(thing2, is.max)
  
  final0 <- jnk[jnk2==TRUE,]
  final <- final0[thing3$is.max==1,]
  
  # o <- match(gs, thing3$jnk.gs[thing3$is.max==1])
  # final <- final[o,]
  # rownames(final) <- gs
  return(final)
}

# the unconcatenated final analysis data set
data.uncat <- lapply(1:length(dat), function(i) {d <- data.ready(dat[[i]])
                                                  n.d <- featureData(d)$gene_symbol
                                                  d2 <- exprs(d)
                                                  study.name <- phenoData(d)$datasetName
                                                  colnames(d2) <- paste(i, "_", colnames(d2), sep="")
                                                  rownames(d2) <- n.d
                                                  return(d2)})
## NOTE:!!! This is something I corrected for in the clustering2 function​
# there are na values in the 12th and 13th study
# find where the na values are and remove those
# 12
id.na.12 = which(is.na(data.uncat[[12]]))
# rowid.na.12 = (id.na.12 - 1)%%35 + 1
# col id of the na values
colid.na.12 = ceiling(id.na.12/35)

# remove the columns with na values
data.uncat[[12]] = data.uncat[[12]][, -unique(colid.na.12)]

# 13
id.na.13 = which(is.na(data.uncat[[13]]))
# rowid.na.13 = (id.na.13 - 1)%%35 + 1
colid.na.13 = ceiling(id.na.13/35)
data.uncat[[13]] = data.uncat[[13]][, -unique(colid.na.13)]


# the naive concatenation of the final analysis data set
# data.ncat <- Reduce(function(x,y) t(merge(t(x),t(y),all=T)), data.uncat)
data.ncat <- do.call(cbind, data.uncat)
# 

par(mfrow=c(4, 4))
for(i in 1:16)
 hist(unlist(data.uncat[[i]]), main=paste("Study", i), xlab="counts")
par(mfrow=c(1,1))

```

We create the function for the following analysis on the concatonated datasets
```{r}
library(matrixStats)
library(dendextend)
library(RColorBrewer)
library(DESeq2)
library(mclust)
<<<<<<< HEAD

par(mfrow=c(3,1), mar=c(7,3,3,1))

################Using hclust method=complete as seen in class 
#replace 11 with length(dat) when fix dataset 12 and 13 
for(i in 1:17){
par(mfrow=c(2,2), mar=c(7,3,3,1))
#obtain dataset for study 1
dat1=as.matrix(data.uncat[[i]])

### do normtransform of counts
if (i != 12){ # the 12th one is already normalized
  dat11=log2(dat1+1)
  dat11=t(dat11)
}else{
  dat11 = dat1
  dat11 = t(dat11)
}

=======
#Function runnign mclust and hclust
clustering <- function(data){
par(mfrow=c(2,2))
dat11=t(as.matrix(data))
>>>>>>> bcc6d8b2544ea6da7a46e440599311fe369e8b27
dists <- dist(dat11)
    
hc <- hclust(dists, method="complete")
dend <- as.dendrogram(hc)

o.dend <- order.dendrogram(dend)

#using mclust 
BIC = mclustBIC((dat11))
mod1 = Mclust(dat11, x = BIC)

####plotting the dendrogram
#color by mclust catebory
labels_colors(dend) <- as.integer(mod1$classification[o.dend])

plot(dend, main=paste("clusters for Study", all.t[i], "by mclust classification")) #all.t contains study labels

#legend("bottom",c("Group1","Batch 6","Batch 7"),fill=c(1,2,3),pch=1,cex=0.5)

####plotting mclust 
plot(BIC)
plot(mod1, what = "classification", dimens=c(2,1), main= paste("Mclust Classification for Study", all.t[i]))

####bargraph of muclust 
str(mod1)
a=table(mod1$classification)
barplot(a, main=paste("Number of Samples in Classifications in Study", all.t[i]))
}


# FUNCTION: clustering2
# OBJECTIVE: to create 4 plots detailing results of hclust (colored by mclust results), 
#            # clusters for mclust determined by BIC,
#            mclust classification and centroids in 2-D,
#            and number of samples in each mclust cluster
# INPUTS: dataset and data.type (what type of transformation was used)
# OUTPUS: 2x2 plot of 4 elements and mclust object
clustering2 <- function(data, data.type){
  par(mfrow=c(2,2))
  where.nas <- is.na(colMeans(data))
  data0 <- data[,where.nas == FALSE]
  dat11 <- t(as.matrix(data0))
  dists <- dist(dat11)
  
  hc <- hclust(dists, method="complete")
  dend <- as.dendrogram(hc)
  o.dend <- order.dendrogram(dend)
  
  #using mclust 
  mod.BIC = mclustBIC((dat11))
  mod1 = Mclust(dat11, x = mod.BIC)
  cols <- brewer.pal(length(unique(mod1$classification)), "Set1")
  
  
  ####plotting the dendrogram
  #color by mclust catebory
  labels_colors(dend) <- cols[mod1$classification[o.dend]]
  plot(dend, main=paste("Heuristic Clustering of\n", data.type, "Data\nby mclust classification")) #all.t contains study labels
  

  ####plotting mclust 
  plot(mod.BIC)
  title("Number of Components\nSelected by BIC")
  plot(mod1, what = "classification", dimens=c(2,1), main="", col=cols)
  title("Mclust Classification and Centroids")
  
  ####bargraph of muclust 
  a=table(mod1$classification)
  barplot(a, main="Number of Samples\nin Each mclust Class", ylim=c(0,nrow(dat11)), col=cols)
  return(mod1)
}

```

```{r}
#===================================# Task 1 #=====================================#
#fnding clusters of each study (17)
par(mfrow=c(3,1), mar=c(7,3,3,1))

for(i in 1:11){
  dat1=as.matrix(data.uncat[[i]])
### do normtransform of counts
dat11=log2(dat1+1)
dat11=t(dat11)
  clustering(dat11)
}

clustering(data.uncat[[12]])
clustering(data.uncat[[13]])

for(i in 14:17){
  dat1=as.matrix(data.uncat[[i]])
### do normtransform of counts
trandat=log2(dat1+1)
  clustering(trandat)
}
```


```{r}
#===================================# Task 2 #=====================================#
# norm transform each study, concatenate, run hclust/mclust
#normalize each study
data.norm <- vector("list", 17)
data.norm[1:11] <- lapply(1:11, function(i) {datn1 <-as.data.frame(data.uncat[[i]])
                                              ctsn=log2(datn1+1)
                                                  return(ctsn)})
data.norm[[12]] <- data.uncat[[12]]
data.norm[[13]]<- data.uncat[[13]]
data.norm[14:17]<- lapply(14:length(dat), function(i) {datn1 <-as.data.frame(data.uncat[[i]])
                                              ctsn=log2(datn1+1)
                                                  return(ctsn)})
#concatonate the normtransformed datasets
# data.normcat <- Reduce(function(x,y) t(merge(t(x),t(y),all=T)), data.norm)
data.normcat <- do.call(cbind, data.norm)

###apply function to norm transformed data
clustering(data.normcat)
```

```{r}
#===================================# Task 3 #=====================================#

# Quantile Normalization each study, concatenate, run hclust /mclust
source("https://bioconductor.org/biocLite.R")
biocLite("preprocessCore")

#concatenate, run quantile normalization, take log (then transpose as needed), then run hclust /mclust
#normalize.quantiles(x,copy=TRUE) package: PreprocessCore
library(preprocessCore)

# performing quantile normalization on each study
data.quant <- lapply(1:length(data.uncat), function(i) normalize.quantiles(data.uncat[[i]], copy=TRUE))

par(mfrow=c(4, 4))
for(i in 1:16)
 hist(unlist(data.quant[[i]]), main=paste("Study", i), xlab="counts")
par(mfrow=c(1,1))

# merging them into one concatenated dataset
data.qnormcat <- Reduce(function(x,y) t(merge(t(x),t(y),all=T)), data.quant)

# clustering with hclust and mclust
c <- clustering2(data.qnormcat, "Quantile Normalized")

#===================================# Task 4 #=====================================#
# Batch Mean Censoring each study, concatenate, run hclust
# log2 transform the data except for the 12th study since it's already normalized
data.norm <- vector("list", 17)
data.norm[1:11] <- lapply(1:11, function(i) {datn1 <-as.data.frame(data.uncat[[i]])
                                              ctsn=log2(datn1+1)
                                                  return(ctsn)})
data.norm[[12]] <- data.uncat[[12]]
data.norm[13:17]<- lapply(13:length(dat), function(i) {datn1 <-as.data.frame(data.uncat[[i]])
                                              ctsn=log2(datn1+1)
                                                  return(ctsn)})
# concatenate the 17 log2 normalized datasets
data.normcat <- Reduce(function(x,y) t(merge(t(x),t(y),all=T)), data.norm)

# calculate the batch mean with respect to the 35 genes
data.rowmean = lapply(data.norm, function(data) apply(data, 1, mean))
# subtract the mean
data.bmcuncat = lapply(1:length(data.norm), function(ix) data.norm[[ix]] - data.rowmean[[ix]])
# concatenate the 17 bmc normalized dataset
data.bmccat <- Reduce(function(x,y) t(merge(t(x),t(y),all=T)), data.bmcuncat)
clustering2(data.bmccat, "BMC")

# ComBat: concatenate the norm transformed data (data.normcat) and the quantile normalized data (data.qnormcat) and then run ComBat on the data set to adjust for batch effects, treat each study as a known batch.
library(sva)
batch.id.list = lapply(1:length(data.uncat), function(batch.id) rep(batch.id, ncol(data.uncat[[batch.id]])))
batch.id.unlist = as.factor(unlist(batch.id.list))

data.normComBat <- ComBat(data.normcat, batch.id.unlist, par.prior = TRUE, prior.plots = FALSE,
  mean.only = FALSE, ref.batch = NULL, BPPARAM = bpparam("SerialParam"))
clustering2(data.normComBat, "normComBat")

# data.qnormComBat <- ComBat(data.qnormcat, batch.id.unlist, par.prior = TRUE, prior.plots = FALSE,
#   mean.only = FALSE, ref.batch = NULL, BPPARAM = bpparam("SerialParam"))
# clustering2(data.qnormComBat, "qnormComBat")
#===================================# Task 5 #=====================================#
# KM curves in Survival data in phenodata
```

