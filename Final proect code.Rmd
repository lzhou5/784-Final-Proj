---
title: "Final project code"
author: "Names"
date: "11/16/2017"
output: html_document
---
# Introduction 
Laura 
  For our final project, we aimed to confirm and explore the results in Figure 6 of the paper "CoINcIDE: A framework for discovery of patient subtypes across multiple datasets." We are interested in identifiying latent subtypes in breast cancer and explore how `hclust` and `mclust` results compare with the new CoINcIDE method. 
  
##Background on Breast Cancer
Peiyao

##CoiNcide Paper Reivew
  Laura 
  The paper "CoINcIDE: A framework for discovery of patient subtypes across multiple datasets" uses the dataset `curatedBreastData`, which is available as an R package. This paper presents a new method, CoINcIDE, which identifies patient subtypes through unsupervised clustering across multiple datasets. This provides more clinical utliltity that most current methods are unable to repliate. CoINcIDE discovers replicable patient subtypes by finding agreement across dataset-specific clusterings from multiple datasets. It clusters individual datasets, represented as nodes in a network, and assigns edges between similar clusters across data sets to create a network, then it identifies the subtypes through community detection. These final subtypes are defined by meta-clusters of tightly connected clusters within this network. An additional advantage of CoINcIDE is that it requires no between-dataset transformations. 

##Project Objectives
Peiyao
  The primary objectives our our paper were to (1) to determine number of latent subtypes, (2) to determine number of samples in each subtype, and (3) compare with COINCIDE paper. Specifically, 
##Figure 6 Discussion
Shaina
  *include why we use mclust
# Data Managment 
Shaina
```{r message=FALSE}
#source("https://bioconductor.org/biocLite.R")
#biocLite("curatedBreastData")

library("curatedBreastData")
library(SummarizedExperiment)
library(Biobase)

data(curatedBreastDataExprSetList)
cbd <- curatedBreastDataExprSetList
str(cbd[[1]])
str <- unique(protocolData(cbd[[1]])$labelDescription)

grepl("breast", str, ignore.case=T)
```

To obtain the same dataset as the paper, we had to apply two filters: (1) datsets with at least 30 samples and (2) has at least the 35 genes in PAM50. 
```{r}
#===================================# Getting the same dataset #=====================================#
#===# apply filters
samp.size <- sapply(1:length(cbd), function(i) nrow(protocolData(cbd[[i]])))
cut1 <- samp.size > 30 # checking which/how many have at least 30 samples

 #== making the first cut
names.cut1 <- names(cbd)[cut1]
cbd.cut1 <- cbd[names.cut1]

all.t <- sapply(1:34, function(i) strsplit(as.character(unique(phenoData(cbd[[i]])$datasetName)), "_")[[1]][2])
datnCuts <- cbind(all.t, cut1) # all genes and which made first cut
geo.plat.id <- sapply(1:34, function(i) strsplit(as.character(unique(phenoData(cbd[[i]])$datasetName)), "_")[[1]][3])

batch.id0 <- sapply(1:34, function(i) strsplit(as.character(unique(phenoData(cbd[[i]])$datasetName)), "_")[[1]][4])
batch.id <- ifelse(batch.id0 == "all", "", batch.id0)
#featureData(cbd[[1]])$probe

#namesofthing <- sapply(1:34, function(i) as.character(unique(phenoData(cbd[[i]])$datasetName)))


dat1 <- subset(cbd, subset=c(cut1 == 1))

#== making the second cut 
# pam50 gene set
gs0 <- c("GRB7 CEP55 MYBL2 KRT5 CDC20 UBE2C CDH3 EXO1 MELK MIA KRT14 BAG1 BIRC5 BLVRA CCNB1 CCNE1 CDC6 CENPF EGFR ERBB2 ESR1 FOXA1 FOXC1 KIF2C KRT17 MAPT MDM2 MKI67 MMP11 MYC PGR RRM2 SFRP1 SLC39A6 TYMS")
gs <- unlist(strsplit(gs0, " "))
length(gs)

cut2 <- sapply(1:length(cbd), function(i) all(gs %in% featureData(cbd[[i]])$gene_symbol))
  
# summary of which experiments made which cuts
datnCuts <- data.frame(all.t, cut1, cut2)
datnCuts[["both.cuts"]] <- with(datnCuts, cut1*cut2)
datnCuts[["sampsize"]] <- samp.size
datnCuts[["real.cut"]] <- with(datnCuts, cut2*(sampsize > 47))
datnCuts[["batch.id"]] <- batch.id
datnCuts[["geo.plat.id"]] <- geo.plat.id

datnCuts

# dataset with only those experiments that made both cuts
dat <- cbd[datnCuts$real.cut == 1]
```

Below is a summary of the datasets used in our analysis. As seen in Table 1 of the paper, we have obtained the same datasets. 
```{r}
#Table 1: Summary of our dataset 
table1 <- datnCuts[datnCuts$real.cut==1, c("all.t","batch.id","geo.plat.id","sampsize")]
names(table1) <- c("ID","Batch ID","GEO Platform ID","Samples (n)")
table1
```

Before we can run our project analysis on the dataset, there was one more filter that had to be applied. The format of the final datasets should only be the last 35 genes
```{r}
#== instructions for removing duplicate genes_symbols
# For duplicated gene symbols linked to different probes in an array, the probe linked to that
# specific gene with the highest variance across all samples was kept.
# Additional Files 2

#=== FUNCTION: data.ready
# OBJECTIVE: for one dataset, this returns the 35 pam50 genes with the largest variance
# INPUTS:  one dataset from dat
# OUTPUT: dataset without replicates
data.ready <- function(dat){
  jnk <- dat
  jnk2 <- featureData(jnk)$gene_symbol %in% gs

  jnk.gs <- featureData(jnk)$gene_symbol
  jnk.vars <- apply(exprs(jnk), 1, function(x) var(x, na.rm=TRUE))
  
  thing <- data.frame(jnk.gs, jnk.vars)
  thing2 <- thing[thing$jnk.gs %in% gs,]

  #=== FUNCTION: compare.to.max
  # OBJECTIVE: compare the value in a row of a matrix to the max value in the cluster
  # INPUTS: the dataset (data), the row index (i), the cluster variable (clust)
  # OUTPUTS: indicator variable of whether the given row matches the cluster max
  compare.to.max <- function(i, data=thing2, clust="jnk.gs"){
    d <- data[[clust]]
    c <- d[i]
    max.c <- max(data[d == c,"jnk.vars"])
    is.max <- as.numeric(data[i,"jnk.vars"] == max.c)
    
    return(is.max)
  }
  
  is.max <- sapply(1:nrow(thing2), compare.to.max)
  
  thing3 <- data.frame(thing2, is.max)
  
  final0 <- jnk[jnk2==TRUE,]
  final <- final0[thing3$is.max==1,]
  
  # o <- match(gs, thing3$jnk.gs[thing3$is.max==1])
  # final <- final[o,]
  # rownames(final) <- gs
  return(final)
}
```

Thus, our final 17 datasets are created below using the functions defined above. 
```{r}
# the unconcatenated final analysis data set
data.uncat <- lapply(1:length(dat), function(i) {d <- data.ready(dat[[i]])
                                                  n.d <- featureData(d)$gene_symbol
                                                  d2 <- exprs(d)
                                                  study.name <- phenoData(d)$datasetName
                                                  colnames(d2) <- paste(i, "_", colnames(d2), sep="")
                                                  rownames(d2) <- n.d
                                                  return(d2)})
## NOTE:!!! This is something I corrected for in the clustering2 functionâ€‹
# there are na values in the 12th and 13th study
# find where the na values are and remove those
# 12
id.na.12 = which(is.na(data.uncat[[12]]))
# rowid.na.12 = (id.na.12 - 1)%%35 + 1
# col id of the na values
colid.na.12 = ceiling(id.na.12/35)

# remove the columns with na values
data.uncat[[12]] = data.uncat[[12]][, -unique(colid.na.12)]

# 13
id.na.13 = which(is.na(data.uncat[[13]]))
# rowid.na.13 = (id.na.13 - 1)%%35 + 1
colid.na.13 = ceiling(id.na.13/35)
data.uncat[[13]] = data.uncat[[13]][, -unique(colid.na.13)]
```

# Data Analysis 
Laura
  To observe our final 17 datasets, we create histograms for each study of the counts, summarized in Figure 1 below. 
```{r}
#Figure 1
par(mfrow=c(4, 4), mar=c(5,3,3,1))
for(i in 1:17)
 hist(unlist(data.uncat[[i]]), main=paste("Study", all.t[[i]]), xlab="counts")
par(mfrow=c(1,1))
```
  
  From Figure 1 above, we note that Study 18728 seemed to have already been transformed. The paper did not discuss how this study was transformed. Thus, we did not transform this dataset and assumed it was a normtransform. 
  
  To run the analysis in each of the tasks described above, we will use the `clustering` functions below. 
```{r}
library(matrixStats)
library(dendextend)
library(RColorBrewer)
library(DESeq2)
library(mclust)

# FUNCTION: clustering2
# OBJECTIVE: to create 4 plots detailing results of hclust (colored by mclust results), 
#            # clusters for mclust determined by BIC,
#            mclust classification and centroids in 2-D,
#            and number of samples in each mclust cluster
# INPUTS: dataset and data.type (what type of transformation was used)
# OUTPUS: 2x2 plot of 4 elements and mclust object
clustering2 <- function(data, data.type){
  par(mfrow=c(2,2))
  where.nas <- is.na(colMeans(data))
  data0 <- data[,where.nas == FALSE]
  dat11 <- t(as.matrix(data0))
  dists <- dist(dat11)
  
  hc <- hclust(dists, method="complete")
  dend <- as.dendrogram(hc)
  o.dend <- order.dendrogram(dend)
  
  #using mclust 
  mod.BIC = mclustBIC((dat11))
  mod1 = Mclust(dat11, x = mod.BIC)
  cols <- brewer.pal(length(unique(mod1$classification)), "Set1")
  
  
  ####plotting the dendrogram
  #color by mclust catebory
  labels_colors(dend) <- cols[mod1$classification[o.dend]]
  plot(dend, main=paste("Heuristic Clustering of\n", data.type, "Data\nby mclust classification")) #all.t contains study labels
  

  ####plotting mclust 
  plot(mod.BIC)
  title("Number of Components\nSelected by BIC")
  plot(mod1, what = "classification", dimens=c(2,1), main="", col=cols)
  title("Mclust Classification and Centroids")
  
  ####bargraph of muclust 
  a=table(mod1$classification)
  barplot(a, main="Number of Samples\nin Each mclust Class", ylim=c(0,nrow(dat11)), col=cols)
  return(mod1)
}

#FUNCTION: clustering3
# OBJECTIVE: same as function `clustering2` except with a normtransform
# INPUTS: dataset and data.type (what type of transformation was used)
# OUTPUS: 2x2 plot of 4 elements and mclust object with log2 transform
clustering3 <- function(data, data.type){
  par(mfrow=c(2,2))
  where.nas <- is.na(colMeans(data))
  data0 <- data[,where.nas == FALSE]
  dat11 <- t(as.matrix(data0))
  dat11=log2(dat11+1)
  dists <- dist(dat11)
  
  hc <- hclust(dists, method="complete")
  dend <- as.dendrogram(hc)
  o.dend <- order.dendrogram(dend)
  
  #using mclust 
  mod.BIC = mclustBIC((dat11))
  mod1 = Mclust(dat11, x = mod.BIC)
  cols <- brewer.pal(length(unique(mod1$classification)), "Set1")
  
  
  ####plotting the dendrogram
  #color by mclust catebory
  labels_colors(dend) <- cols[mod1$classification[o.dend]]
  plot(dend, main=paste("Heuristic Clustering of\n", data.type, "Data\nby mclust classification")) #all.t contains study labels
  

  ####plotting mclust 
  plot(mod.BIC)
  title("Number of Components\nSelected by BIC")
  plot(mod1, what = "classification", dimens=c(2,1), main="", col=cols)
  title("Mclust Classification and Centroids")
  
  ####bargraph of muclust 
  a=table(mod1$classification)
  barplot(a, main=paste("Number of Samples\n in Each mclust Class",all.t[i]), ylim=c(0,nrow(dat11)), col=cols)
  return(mod1)
}
```

## Task 1: Clustering within each Study 
  In our first task, we are interested in establishing the latent subtypes within each of the studies. 
```{r}
#===================================# Task 1 #=====================================#
#fnding clusters of each study
for(i in 1:11){
  dat1=as.matrix(data.uncat[[i]])
  clustering3(dat1, "NormTransform")
}

#pre-transformed study 18728
clustering2(data.uncat[[12]], "'Norm'Transform ")

for(i in 13:17){
  dat1=as.matrix(data.uncat[[i]])
  clustering3(trandat)
}
```

We summarize the total number of clusters and the number of samples in each cluster by study in the following figure. 
```{r}
### outputting bar plot for all 17 studies
#first 11 studies 
par(mfrow=c(3,4), mar=c(5,3,3,1))
for(i in 1:11){
  data=data.uncat[[i]]
  where.nas <- is.na(colMeans(data))
  data0 <- data[,where.nas == FALSE]
  dat11 <- t(as.matrix(data0))
  dat11=log2(dat11+1)
  
  #using mclust 
  mod.BIC = mclustBIC((dat11))
  mod1 = Mclust(dat11, x = mod.BIC)
  cols <- brewer.pal(length(unique(mod1$classification)), "Set1")

  ####bargraph of muclust 
  a=table(mod1$classification)
  barplot(a, main=paste("Study", all.t[[i]]), ylim=c(0,nrow(dat11)), col=cols)
  }

#pre-transformed study 18728
  data=data.uncat[[12]]
  where.nas <- is.na(colMeans(data))
  data0 <- data[,where.nas == FALSE]
  dat11 <- t(as.matrix(data0))
  
  #using mclust 
  mod.BIC = mclustBIC((dat11))
  mod1 = Mclust(dat11, x = mod.BIC)
  cols <- brewer.pal(length(unique(mod1$classification)), "Set1")

  ####bargraph of muclust 
  a=table(mod1$classification)
  barplot(a, main=paste("Study", all.t[[i]]), ylim=c(0,nrow(dat11)), col=cols)

#remaining studies
for(i in 13:17){
  data=data.uncat[[i]]
  where.nas <- is.na(colMeans(data))
  data0 <- data[,where.nas == FALSE]
  dat11 <- t(as.matrix(data0))
  dat11=log2(dat11+1)
  
  #using mclust 
  mod.BIC = mclustBIC((dat11))
  mod1 = Mclust(dat11, x = mod.BIC)
  cols <- brewer.pal(length(unique(mod1$classification)), "Set1")

  ####bargraph of muclust 
  a=table(mod1$classification)
  barplot(a, main=paste("Study", all.t[[i]]), ylim=c(0,nrow(dat11)), col=cols)
  }
```

  As seen above, the number of clusters in each study ranges from 2 to 9 clusters. The most common number of clusters (determined by BIC) is 4. 
  
##Task 2: Clustering within Normtransformed Concatonated dataset
  In Task 2, we are interested in the number of clusters in the concatonated data of all the studies. Each study is first normtransformed before we concatonate and cluster. 
```{r}
#===================================# Task 2 #=====================================#
#normalize each study
data.norm <- vector("list", 17)
data.norm[1:11] <- lapply(1:11, function(i) {datn1 <-as.data.frame(data.uncat[[i]])
                                              ctsn=log2(datn1+1)
                                                  return(ctsn)})
data.norm[[12]] <- data.uncat[[12]]
data.norm[13:17]<- lapply(13:length(dat), function(i) {datn1 <-as.data.frame(data.uncat[[i]])
                                              ctsn=log2(datn1+1)
                                                  return(ctsn)})
#concatonate the normtransformed datasets
data.normcat <- do.call(cbind, data.norm)

#apply function to norm transformed data
clustering2(data.normcat, "Norm Transform")
```

##Task 3: Clustering within Quantile Normalized Concatonated Dataset
```{r}
#===================================# Task 3 #=====================================#

# Quantile Normalization each study, concatenate, run hclust /mclust
source("https://bioconductor.org/biocLite.R")
biocLite("preprocessCore")

#concatenate, run quantile normalization, take log (then transpose as needed), then run hclust /mclust
#normalize.quantiles(x,copy=TRUE) package: PreprocessCore
library(preprocessCore)

# performing quantile normalization on each study
data.quant <- lapply(1:length(data.uncat), function(i) normalize.quantiles(data.uncat[[i]], copy=TRUE))

par(mfrow=c(4, 4))
for(i in 1:16)
 hist(unlist(data.quant[[i]]), main=paste("Study", i), xlab="counts")
par(mfrow=c(1,1))

# merging them into one concatenated dataset
data.qnormcat <- Reduce(function(x,y) t(merge(t(x),t(y),all=T)), data.quant)

# clustering with hclust and mclust
c <- clustering2(data.qnormcat, "Quantile Normalized")
```

## Task 4: Clustering within Batch Mean Censored Concatonated Dataset
```{r}
#===================================# Task 4 #=====================================#
# Batch Mean Censoring each study, concatenate, run hclust
# log2 transform the data except for the 12th study since it's already normalized
data.norm <- vector("list", 17)
data.norm[1:11] <- lapply(1:11, function(i) {datn1 <-as.data.frame(data.uncat[[i]])
                                              ctsn=log2(datn1+1)
                                                  return(ctsn)})
data.norm[[12]] <- data.uncat[[12]]
data.norm[13:17]<- lapply(13:length(dat), function(i) {datn1 <-as.data.frame(data.uncat[[i]])
                                              ctsn=log2(datn1+1)
                                                  return(ctsn)})
# concatenate the 17 log2 normalized datasets
data.normcat <- Reduce(function(x,y) t(merge(t(x),t(y),all=T)), data.norm)

# calculate the batch mean with respect to the 35 genes
data.rowmean = lapply(data.norm, function(data) apply(data, 1, mean))
# subtract the mean
data.bmcuncat = lapply(1:length(data.norm), function(ix) data.norm[[ix]] - data.rowmean[[ix]])
# concatenate the 17 bmc normalized dataset
data.bmccat <- Reduce(function(x,y) t(merge(t(x),t(y),all=T)), data.bmcuncat)
clustering2(data.bmccat, "BMC")

# ComBat: concatenate the norm transformed data (data.normcat) and the quantile normalized data (data.qnormcat) and then run ComBat on the data set to adjust for batch effects, treat each study as a known batch.
library(sva)
batch.id.list = lapply(1:length(data.uncat), function(batch.id) rep(batch.id, ncol(data.uncat[[batch.id]])))
batch.id.unlist = as.factor(unlist(batch.id.list))

data.normComBat <- ComBat(data.normcat, batch.id.unlist, par.prior = TRUE, prior.plots = FALSE,
  mean.only = FALSE, ref.batch = NULL, BPPARAM = bpparam("SerialParam"))
clustering2(data.normComBat, "normComBat")

# data.qnormComBat <- ComBat(data.qnormcat, batch.id.unlist, par.prior = TRUE, prior.plots = FALSE,
#   mean.only = FALSE, ref.batch = NULL, BPPARAM = bpparam("SerialParam"))
# clustering2(data.qnormComBat, "qnormComBat")
```

##Task 5: Clustering within ComBat Transformed Dataset
```{r}
#ComBat transform 
``` 

# Summary of Results 
Comparison to Figure 6 of paper 

#References